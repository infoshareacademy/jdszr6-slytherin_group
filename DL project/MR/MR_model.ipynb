{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report, multilabel_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Lenovo/Desktop/Szkolenie/jdszr6-slytherin_group/DL project/MR/archive/sign_mnist_train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/Lenovo/Desktop/Szkolenie/jdszr6-slytherin_group/DL project/MR/archive/sign_mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define features and target\n",
    "x=df.drop(columns='label')\n",
    "y=df['label']\n",
    "\n",
    "# #reshape features into picture like structure & scale \n",
    "# x=x.to_numpy()\n",
    "# x=x.reshape(27455,28,28)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of x_train and y_train:  (21964, 784) (21964,)\n",
      "Shapes of x_val and y_val:  (5491, 784) (5491,)\n",
      "y_train values : [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n",
      "y_val values : [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "#Split data in test & train\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y,test_size=0.2,stratify=y)\n",
    "\n",
    "print('Shapes of x_train and y_train: ',x_train.shape,y_train.shape)\n",
    "print('Shapes of x_val and y_val: ',x_val.shape,y_val.shape)\n",
    "\n",
    "print('y_train values :', np.sort(y_train.unique()))\n",
    "print('y_val values :',np.sort(y_val.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 5, 5, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 128)               102528    \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 115,321\n",
      "Trainable params: 115,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "MODEL TRAINING & VALIDATION:\n",
      "Epoch 1/5\n",
      "687/687 [==============================] - 16s 22ms/step - loss: 1.0681 - accuracy: 0.6786 - val_loss: 0.2673 - val_accuracy: 0.9155\n",
      "Epoch 2/5\n",
      "687/687 [==============================] - 16s 24ms/step - loss: 0.1229 - accuracy: 0.9688 - val_loss: 0.0514 - val_accuracy: 0.9929\n",
      "Epoch 3/5\n",
      "687/687 [==============================] - 15s 21ms/step - loss: 0.0233 - accuracy: 0.9977 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "687/687 [==============================] - 17s 25ms/step - loss: 0.0146 - accuracy: 0.9968 - val_loss: 0.1903 - val_accuracy: 0.9282\n",
      "Epoch 5/5\n",
      "687/687 [==============================] - 21s 30ms/step - loss: 0.0219 - accuracy: 0.9941 - val_loss: 0.0020 - val_accuracy: 0.9998\n"
     ]
    }
   ],
   "source": [
    "# Define  & train the model without regularization\n",
    "model1 = tf.keras.models.Sequential([\n",
    "                                                         \n",
    "  # Add convolutions and max pooling\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28,1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "  # Add the same layers as before\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model1.summary()\n",
    "\n",
    "# Use same settings\n",
    "model1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "print(f'\\nMODEL TRAINING & VALIDATION:')\n",
    "history1= model1.fit(x_train.to_numpy().reshape(x_train.shape[0],28,28)/255, y_train, epochs=5,validation_data=(x_val.to_numpy().reshape(x_val.shape[0],28,28)/255,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20a9e06a1eee47c4abbed4ec8225ad91d78d9800d202b71b6b0a6e47016c6abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
